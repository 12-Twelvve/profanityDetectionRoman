{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b88b594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob # finds all the pathnames matching pattern\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fd7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP package\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f328e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/l3gion/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "556a12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe from json raw data\n",
    "def make_dataframe_from_json():\n",
    "    arr = np.array([])\n",
    "    path_to_json_data = './GoogleExtensionScrape/scrapedata/'\n",
    "    file_list = glob.glob(os.path.join(path_to_json_data, '*.json'))\n",
    "    for file in file_list:\n",
    "        json_array = pd.read_json(file).comments.values\n",
    "        arr = np.append(arr, json_array)\n",
    "    df = pd.DataFrame(arr, columns =['comments'])\n",
    "    df['profanity'] = 0\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1962cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_words =['mug','mugi','cock','lado','bitch','jantha','jatha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ff745fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the empty string with NAN value\n",
    "def naRow(r):\n",
    "    x = str(r).strip()\n",
    "    if x == '' or x == 'nan':\n",
    "        return np.nan\n",
    "    return x\n",
    "\n",
    "# english word removal function\n",
    "def removeEnglishWord(sent):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(sent) if w.lower() not in words or w.lower() in special_words or not w.isalpha())\n",
    "# remove repeating letters\n",
    "import re\n",
    "def remove_recurring_letters(sentence):\n",
    "    words = sentence.split()\n",
    "    modified_sentence = []\n",
    "    for word in words:\n",
    "        modified_word = re.sub(r\"(.)\\1+\", r\"\\1\", word)\n",
    "        modified_sentence.append(modified_word)\n",
    "    return ' '.join(modified_sentence)\n",
    "\n",
    "\n",
    "def drop_duplicates_null(df):\n",
    "    # remove duplicates \n",
    "    df = df.drop_duplicates()\n",
    "    # replace empty comment with NAN\n",
    "    df['comments'] = df['comments'].apply(naRow)\n",
    "    #delete the NAN value\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Clean function\n",
    "def clean_comment(df):\n",
    "    # clean special character except a-z\n",
    "    df['comments'] = df['comments'].str.replace(r'[^a-zA-Z]', ' ', regex=True)\n",
    "    # remove english words only while training \n",
    "    df['comments'] = df.apply(lambda row : removeEnglishWord(row['comments']), axis=1)\n",
    "    # remove double + letters\n",
    "    df['comments'] = df['comments'].apply(lambda x:remove_recurring_letters(x))\n",
    "    # convert to lower letters\n",
    "    df['comments'] = df['comments'].apply(lambda x: ' '.join([word.lower() for word in x.split()]))\n",
    "    df = drop_duplicates_null(df)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370cb9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d34cb729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/l3gion/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import ntr \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stop_words(df):\n",
    "    stopwords_nepali = set(stopwords.words('nepali'))\n",
    "    # stop words in roman\n",
    "    stopwords_roman = list(map(ntr.nep_to_rom, stopwords_nepali))\n",
    "    # remove stop words\n",
    "    df['comments'] = df['comments'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stopwords_roman]))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0d6566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove single letter in comments\n",
    "def remove_single_letter_words(sentence):\n",
    "    pattern = r\"\\b\\w\\b\"\n",
    "    modified_sentence = re.sub(pattern, \"\", sentence)\n",
    "    return modified_sentence\n",
    "def remove_clean_single_letter(df):\n",
    "    # remove single letter comment\n",
    "    df['comments'] = df['comments'].apply(lambda x: remove_single_letter_words(x))\n",
    "    # remove rows with empty set\n",
    "    df['comments'] = df['comments'].apply(naRow)\n",
    "    df = drop_duplicates_null(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b5feb5",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c7f6af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nasty is talented as f**ck  No matter what</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDK about business  contract or what but nasty...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uniq you playing too much man  looks like you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bring Nasty on the podcast plz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bring NASTY in podcast lets hear frm his side</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  profanity\n",
       "0         Nasty is talented as f**ck  No matter what          1\n",
       "1  IDK about business  contract or what but nasty...          0\n",
       "2  Uniq you playing too much man  looks like you ...          0\n",
       "3                     Bring Nasty on the podcast plz          0\n",
       "4      Bring NASTY in podcast lets hear frm his side          0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "# df = make_dataframe_from_json()\n",
    "df = pd.read_csv('./test1.3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1056081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94259/3230717631.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comments'] = df['comments'].apply(naRow)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idk uniq</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniq playing loks shit ain gona</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>podcast plz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>podcast lets frm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          comments  profanity\n",
       "0                               ck          1\n",
       "1                         idk uniq          0\n",
       "2  uniq playing loks shit ain gona          0\n",
       "3                      podcast plz          0\n",
       "4                 podcast lets frm          0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean df\n",
    "df = clean_comment(df)\n",
    "# remove stopwords \n",
    "df = remove_stop_words(df)\n",
    "# remove single letter and clean empty string\n",
    "df = remove_clean_single_letter(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f4ca424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_df_test', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "572664ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idk uniq</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniq playing loks shit ain gona</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>podcast plz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>podcast lets frm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          comments  profanity\n",
       "0                               ck          1\n",
       "1                         idk uniq          0\n",
       "2  uniq playing loks shit ain gona          0\n",
       "3                      podcast plz          0\n",
       "4                 podcast lets frm          0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1021a",
   "metadata": {},
   "source": [
    "after updating the profanity to each comments manaually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255fc6cd",
   "metadata": {},
   "source": [
    "### Model trianing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f341c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5fdf64b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idk uniq</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniq playing loks shit ain gona</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>podcast plz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>podcast lets frm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          comments  profanity\n",
       "0                               ck          1\n",
       "1                         idk uniq          0\n",
       "2  uniq playing loks shit ain gona          0\n",
       "3                      podcast plz          0\n",
       "4                 podcast lets frm          0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset \n",
    "df = pd.read_csv('./clean_df_test')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20341299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "vectorizer = CountVectorizer()  # or TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['comments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14b02c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['profanity'], test_size=0.2, random_state=42)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "948c07ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d6b403ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----MultinomialNB-----\n",
      "Accuracy: 0.9086538461538461\n",
      "Precision: 0.6756756756756757\n",
      "Recall: 0.78125\n",
      "F1-Score: 0.7246376811594203\n",
      "----Randomforest-----\n",
      "Accuracy: 0.9423076923076923\n",
      "Precision: 0.9545454545454546\n",
      "Recall: 0.65625\n",
      "F1-Score: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "def model_evaluation(classifier):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-Score:\", f1)\n",
    " \n",
    "print(\"----MultinomialNB-----\")\n",
    "model_evaluation(classifier)\n",
    "print(\"----Randomforest-----\")\n",
    "model_evaluation(rf_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6798ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[164  12]\n",
      " [  7  25]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47039993",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "52dbc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_new_comment(new_comment):\n",
    "    new_comment = clean_comment(pd.DataFrame({'comments': [new_comment]}))['comments'][0]\n",
    "    new_comment = remove_stop_words(pd.DataFrame({'comments': [new_comment]}))['comments'][0]\n",
    "    new_comment = remove_clean_single_letter(pd.DataFrame({'comments': [new_comment]}))['comments'][0]\n",
    "    return new_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e747626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_new_comment(new_comment):\n",
    "    return vectorizer.transform([new_comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b482112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomialNB [1]\n",
      "Random Forest [1]\n"
     ]
    }
   ],
   "source": [
    "new_comment = \"k gardai chas mug\"\n",
    "new_comment = preprocess_new_comment(new_comment)\n",
    "X_new = transform_new_comment(new_comment)\n",
    "prediction = classifier.predict(X_new)\n",
    "prediction = rf_classifier.predict(X_new)\n",
    "print('multinomialNB',prediction)\n",
    "print('Random Forest',prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70032a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
